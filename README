If you want to try it I suggest starting with Ubuntu in a virtual machine. You'll need to install some packages:

sudo apt-get install python-numpy python-scipy tv-fonts xterm git

Then run an xterm like this:

/usr/bin/xterm -fg white -bg black -fn teletext &

Then checkout source and run on the example data like this:

git clone git://github.com/ali1234/vhs-teletext.git
cd vhs-teletext
./vbi.py example | ./printer.py

You should now see some packets output.

All the things you need should be available to run this on Windows, but I have not tried it.



In detail:


Step 1 - Capture teletext packets

Compile dumpvbi:

	gcc -o dumpvbi dumpvbi.c

Create a folder for captures:

	mkdir cap0001
	cd cap0001

Do capture:

	../dumpvbi

End capture with ctrl-c and then go back to previous directory:

	cd ..

This produces raw binary files starting at 00000000.vbi. Each file contains 32 
vbi lines sampled from a single frame. Each line is 2048 samples.


Step 2 - Run recovery

Run vbi.py on the sampled data:

	./vbi.py cap0001/ | ./pagesplitter.py cap0001/pages/

This runs the deconvolver and pipes the output into the page splitter, which creates a subfolder with directories for each magazine, and file for each page.


Step 3 - Squash subpages to html:

	./subpagesquash.py cap0001/pages/ cap0001/html-pages/

Outputs hyperlinked html files for each page


Step 4 - Copy font and CSS:

	cp teletext2.ttf teletext4.tff teletext.css cap0001/html-pages/

Now you can view the html files properly:

	xdg-open cap0001/html-pages/100.html
