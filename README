If you want to try it I suggest starting with Ubuntu in a virtual machine. You'll need to install some packages:

	sudo apt-get install python-numpy python-scipy tv-fonts xterm git

Then run an xterm like this:

	/usr/bin/xterm -fg white -bg black -fn teletext &

Then checkout source and run on the example data like this:

	git clone git://github.com/ali1234/vhs-teletext.git

All the things you need should be available to run this on Windows, but I have not tried it.



In detail:




Step 1 - Capture teletext packets

(If you are running in a VM you probably won't be able to use capture hardware.
In that case you must capture in the host OS and then copy in the vbi files.)

Compile dumpvbi:

	sudo apt-get install build-essential
	gcc -o dumpvbi dumpvbi.c

Create a folder for captures:

	mkdir cap0001
	cd cap0001
        mkdir vbi
        cd vbi

Do capture:

	../../dumpvbi

You will need at least 15-30 minutes for good results. 
End capture with ctrl-c and then go back to previous directory:

	cd ../..

This produces raw binary files starting at 00000000.vbi. Each file contains 32 
vbi lines sampled from a single frame. Each line is 2048 samples.




Step 2 - Run recovery

Run vbi.py on the sampled data:

	./vbi.py cap0001/

Step 3 - Page splitter

	./t42cat.py cap0001/t42/ 2> /dev/null | ./pagesplit.py cap0001/pages/


Step 4 - Squash subpages to html:

	./subpagesquash.py cap0001/pages/ cap0001/html-pages/

Outputs hyperlinked html files for each page. You can run this while the page
splitter is still working, and you can run it over and over to get the newest
results.




Step 5 - Copy font and CSS:

	cp teletext2.ttf teletext4.tff teletext.css cap0001/html-pages/

This is needed to make the html files render properly. You can now open 100.html
in firefox from the file manager, or open it from the terminal with:

	xdg-open cap0001/html-pages/100.html

